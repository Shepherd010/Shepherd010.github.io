---
title: 通用微处理器体系结构
date: '2024-11-15 15:19:04'
updated: '2025-01-25 18:49:44'
permalink: /post/universal-microprocessor-architecture-hr7ze.html
comments: true
toc: true
---

# 通用微处理器体系结构

微处理器（英语：Microprocessor，缩写：µP或uP）通常指称一种可编程特殊集成电路，其所有组件小型化至一块或数块集成电路内。用作处理通用资料时，叫作中央处理器（Central Processing Unit），这也是最为人所知的应用，如：AMD Ryzen CPU；专用于图像资料处理的，叫作图形处理器（Graphics Processing Unit），如Nvidia GeForce 40X0 GPU；用于音讯资料处理的，叫作音讯处理单元（Audio Processing Unit）。

微处理器已经无处不在，无论是录像机、智能洗衣机、移动电话等家电产品，还是汽车引擎控制，以及数控机床、导弹精确制导等都要嵌入各类不同的微处理器。微处理器不仅是微型计算机的核心部件，也是各种数字化智能设备的关键部件。国际上的超高速巨型计算机、大型计算机等高端计算系统也都采用大量的通用高性能微处理器建造。

‍

微处理器是计算机系统的核心组件之一，它集成了计算机的主要逻辑功能，包括数据处理和指令执行。下面是对您提到的各个组成部分的简要介绍：

1. **算术逻辑单元 (ALU, Arithmetic Logic Unit)** : ALU 是微处理器中负责执行基本的数学计算（如加法、减法等）和逻辑操作（如AND、OR、NOT等）的部分。它是处理器进行数据处理的核心。
2. **累加器和通用寄存器组**: 累加器是一种特殊的寄存器，主要用于临时存储算术或逻辑运算的结果。通用寄存器组则是一组可以用于多种目的的寄存器，它们可以用来保存数据、地址或其他信息，以支持各种指令的执行。
3. **程序计数器 (Program Counter, PC)** : 程序计数器，有时也称为指令指针，它保存了下一条要执行的指令在内存中的地址。当处理器执行完一条指令后，程序计数器通常会更新到下一个指令的位置，从而实现程序的顺序执行。
4. **时序和控制逻辑部件**: 这一部分负责协调微处理器内各部件的操作，确保指令能够按照正确的顺序被执行。它还负责产生必要的控制信号，以指导数据在不同部件之间的流动。
5. **数据与地址锁存器/缓冲器**: 锁存器/缓冲器用于暂时存储数据或地址信息，以便于它们可以在不同的部件之间传输。例如，在访问内存时，地址锁存器会保存要访问的内存位置的地址，而数据锁存器则用于暂存将要写入或读出的数据。
6. **内部总线**: 内部总线是微处理器内部各部件之间传输数据的通道。它可以分为地址总线、数据总线和控制总线，分别用于传输地址信息、数据信息和控制信号。

**运算器和控制器**是微处理器的两个核心部分，其中：

* **运算器**主要指的是ALU，它负责所有数据的算术和逻辑运算。
* **控制器**则负责取指令、解码指令以及生成控制信号来指挥整个微处理器的工作流程。控制器还包括程序计数器和时序控制逻辑等部件，以确保指令能够正确无误地被执行。

这些组成部分共同协作，使得微处理器能够高效地执行复杂的计算任务和程序控制。

‍

‍

‍

16位微处理器，如8086，主要分为执行部件(EU)和总线接口部件(BIU)两大部分。EU负责指令的执行，包括算术和逻辑运算，其内含有8个16位寄存器用于存储数据、变址及堆栈指针等，并配备有ALU和标志寄存器来处理并记录操作结果的状态。EU中的各组件通过数据总线连接，实现数据的传输。BIU则负责与8086外部总线的交互，包括从存储器中获取指令。通过总线控制逻辑，BIU管理着数据和地址总线与外部8086系统总线之间的连接，8086具备16位的数据总线宽度，允许每次传输16位的数据。

BIU则负责与8086外部总线的交互，包括从存储器中获取指令。它包含一组寄存器，其中包括四个分段寄存器(CS、DS、SS、ES)，用于定义不同的存储空间区域；指令指针(IP)用于指示下一条要执行的指令的位置；内部通信寄存器用于临时存储数据；以及一个指令队列，用于预存取指令流，提高处理效率。BIU还配有一个地址加法器，该加法器能够将分段寄存器的值与偏移量相加，从而计算出20位的物理地址，这使得8086能够访问超过1MB的内存空间。通过总线控制逻辑，BIU管理着数据和地址总线与外部8086系统总线之间的连接，8086具备16位的数据总线宽度，允许每次传输16位的数据。

此外，8086采用了初步的流水线技术，允许取指和执行指令的过程同时进行，从而提高了处理器的工作效率。这种设计让8086能够在执行当前指令的同时，预取下一条或多条指令，进一步提升了系统的性能。

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115183222-b2re3gb.png)​

‍

指令集架构（Instruction Set Architecture，ISA）是计算机体系结构中，介于微处理器架构（Microarchitecture）与操作系统之间的接口。指令集架构用于抽象微处理器底层的具体硬件实现以提供给操作系统一个简洁的硬件接口来管理计算机硬件系统。

ISA 可分为 CISC 和 RISC 两大阵营。CISC 是指复杂指令系统计算机（Complex Instruction Set Computer）；RISC 是指精简指令系统计算机（Reduced Instruction Set Computer）。

2. CISC体系结构  
    CISC 体系结构：通过设置一些功能复杂的指令，把一些原来由软件实现的、常用的功能改用硬件指令实现，以此来提高计算机的执行速度。越来越多的复杂指令被加人指令系统中，逐渐形成了一个庞大且复杂的指令集。

    CISC结构追求的目标是：强化指令功能，减少程序的指令条数，以达到提高性能的目的。早期的计算机系统几乎全都是CISC架构，特别是微型机中 Intel 和 AMD 早期的 CPU 都是纯粹的 CISC体系架构，大量软件也是基于 CISC 架构来开发的，特别是广泛流行的操作系统软件。
3. RISC体系结构  
    20世纪70年代，RISC技术诞生，并在加州大学伯克利分校 David Patterson 和斯坦福大学 John Hennessy 等人的推广下得以广泛实现。

    RISC体系结构的基本思想：尽量简化计算机指令功能，只保留那些功能简单、能在一个节拍内执行完成的指令，而把较复杂的功能用段子程序来实现。 RISC通过减少指令种类、规范指令格式和简化寻址方式等方法，方便处理器内部的并行处理，提高超大规模集成电路(VLSI)器件的使用效率，从而大幅度地提高处理器的性能。

    RISC 指令系统仅包含最常用的简单指令，因此可以通过硬件优化设计，把时钟频率提得很高，从而实现整个系统的高性能。同时，RISC 技术在 CPU 芯片上设置大量寄存器，用来保存常用的数据，以大大减少对存储器的访问，用高速的寄存器访问取代低速的存储器访问，从而提高系统整体性能。
4. ARM 架构、THUMB 架构、RISC-V 架构

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115184013-98xetbx.png)​

‍

伯克利大学在 2010 年启动了 RISC 第五代项目计划，开发了新一代的 RISC 指令集架构：RISC-V。加州大学伯克利分校教授、RISC-V 发明人 David Patterson 曾大胆预言：「**在五到十年内，RISC-V 可能成为世界上最重要的指令集**」

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115184815-eglzct6.png)​

RISC-V 吸取了 RISC 指令集使用以及开发过程的经验，且在设计过程中匹配了现代计算设备的性能与功耗需求，其主要特点包括有：

1. 将指令集划分为一个小型的基本指令集以及若干个可选的扩展指令集。RISC-V 包含 32 位以及 64 位的指令集系统。以 32 位指令集为例子，RISC-V 规定 32 位整型指令集（RV32I）为基本指令集架构，即所有基于 RISC-V 实现的 32 位微处理器都必须实现 RV32I 指令集。从另一方面来说，一个仅实现了 RV32I 指令集的微处理器，在不考虑性能的情况下，都可以执行任意的编译为 RISC-V 的程序。而根据微处理器面向的场景与功能需求，可以实现额外的扩展指令集，如乘除指令集（M）、压缩指令集（C）等等。目前，RV32I 以及 RV64I 指令集都已经处于冻结的状态，在未来也不会发生任何改变，这种模块化的设计吸取了 x86 的教训，为了保持二进制代码的向后兼容性，同时维持基本指令集的简洁不变，所有新加入的指令将会以扩展指令集的方式存在[3]。
2.  指令集架构与具体微处理器架构的严格分离。对于指令集架构的设计者来说，在指令集当中对于特定微处理器实现添加某条指令会对性能以及成本带来提升，但是却对其他的实现或者未来的实现带来负担。以 MIPS 的分支延迟间隙为例子，该设计为了优化早期的 MIPS 流水线设计中的分支指令所带来的性能损耗问题，而定义分支的操作固定在分支指令的下一条指令执行完后再执行，而程序员/编译器则负责往这一间隙中填充有用的指令。然而，这种设计对于后来更深的 MIPS 流水线设计以及更先进的分支预测策略来说成为了一种累赘，使用 MIPS 实现的微处理器为了保证指令集的向后兼容性，需要花费大量的时间适配该行为。RISC-V 为了避免这种情况的发生，在指令集设计过程中避免了对微处理器架构的过多设计，保持从低功耗的嵌入式微处理器到大型数据仓库式微处理器的一致性。
3. 开源指令集。RISC-V 属于一个开放的非盈利性质的基金会，其不受任何一个公司的兴起或者没落所影响。RISC-V 指令集可以供任何个人或者团体免费使用，包括开发基于 RISC-V 的芯片或者软件，而不需要支付任何授权的费用。这对于工业界来说 RISC-V 是一大优势，通过复用开源的基于 RISC-V 的 IP 软核设计，可以极大的降低微处理器实现的门槛。同时，对于学术界来说，基于 RISC-V 的微处理器实现也可以平稳的转移到商用微处理器上。

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115184358-uzm7rfe.png)​

‍

放眼国内，RISC-V 的热度也在不断上涨.

‍

2019 年，在中国科学院支持下，由 中国科学院计算技术研究所 牵头发起 “香山” 高性能开源 RISC-V 处理器项目，研发出目前国际上性能最高的开源高性能 RISC-V 处理器核 “香山”，在全球最大的开源项目托管平台 GitHub 上获得超过 4100 个星标（Star），形成超过 550 个分支（Fork），成为国际上最受关注的开源硬件项目之一，得到国内外企业的积极支持 —— 16 家企业联合发起开源芯片创新联合体北京开源芯片研究院（Beijing Institute of Open Source Chip, BOSC），围绕“香山” 进一步联合开发，形成示范应用，加速 RISC-V 生态建设。

‍

‍

香山开源项目有两方面的目标，其一是建立一个像Linux那样的开源RISC-V核主线并成为世界级的体系结构创新平台，既能被工业界广泛应用，又能支持学术界试验创新想法；其二是在开发过程中探索高性能处理器的敏捷开发流程，建立一套基于开源工具的高性能处理器设计、实现、验证流程，提高处理器开发效率、降低处理器开发门槛。

‍

‍

**香山处理器第一版（雁栖湖架构）**  支持 RV64GC 指令集，已在 2021 年 7 月投片，在 28nm 的工艺节点下达到 1.3GHz 的频率。2022 年 1 月，雁栖湖芯片回片并成功点亮，能够正确运行 Linux/Debian 等复杂操作系统，在 DDR4-1600 环境下初步实测 SPEC CPU2006 性能超过 7 分 @1GHz，更完整的 CPU 与 DDR 性能调优正在进行中。

**香山处理器第二版（南湖架构）**  支持 RV64GCBK 指令集，已在 2022 年 3 月完成 RTL 代码冻结，正在进行后端设计验证流程并将在 2022 年上半年完成投片，目标是在 14nm 工艺节点下频率达到 2GHz。

**香山处理器第三版（昆明湖架构）**  正在进行中

‍

‍

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115190138-gsujnxm.png)​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115190216-3yt75y3.png)​

香山处理器是乱序六发射结构设计，香山处理器前端流水线包括分支预测单元、取指单元、指令缓冲等单元，顺序取指。后端包括译码、重命名、重定序缓冲、保留站、整型/浮点寄存器堆、整型/浮点运算单元。我们将访存子系统分离开，包括两条 load 流水线，两条 store addr 流水线，两条 store data 流水线，以及独立的 load 队列和 store 队列，store buffer 等。缓存包括 ICache、DCache、L2/L3 Cache (HuanCun)、TLB 和预取器等模块。各部分在流水线中的位置以及参数配置可以从下图中获得。

​![image](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/image-20241115190601-rmapat9.png)​

香山处理器的 `Memblock`​ 包含核内的访存流水线及队列, 以及与访存流水线紧耦合的一级数据缓存. 我们使用 `访存单元`​ 一词来指代 `Memblock`​这一部分.

​![整体流水线](https://raw.githubusercontent.com/Shepherd010/Shepherd010.github.io/master/images/network-asset-nanhu-memblock-20241115190920-ftz74vf.png)​

香山处理器(南湖架构)核内的访存单元如上图所示. 其中包含两条 load 流水线, 彼此分离的两条 sta 流水线 和两条 std 流水线. load queue 和 store queue 负责维护访存指令的顺序信息. load queue 会在 load 指令在一级缓存中缺失时负责监听后续的重填结果并执行写回操作. store queue 负责在指令提交之前暂存 store 的数据, 并为 store 向 load 的前递提供数据.

在 store 指令提交之后, store queue 会将其中的数据搬运到 committed store buffer. committed store buffer 会以缓存行为单位对 store 的写请求进行合并, 在接近满的时候将合并后的多个 store 写请求一并写入到一级数据缓存中.

一级数据缓存 对核内访存组件暴露两个位宽为64的读端口和一个与一级数据缓存行宽度相同的写端口, 以及一个数据重填端口. 数据重填端口的宽度数据缓存和 l2 缓存之间的总线宽度决定. 目前, 南湖架构的数据重填端口宽度为 256 bit. 一级数据缓存使用 TileLink 总线协议.

MMU, 亦即 Memory Management Unit，在处理器中主要负责将虚拟地址翻译成物理地址，然后用这个物理地址去访存。同时也会进行权限检查，比如是否可写，可执行. 香山的 MMU 包含 TLB, L2TLB, Repeater, PMP & PMA 等组件.

多个组件共同配合实现了香山处理器的乱序访存机制, 参见 访存机制介绍 一节. 除此之外, 有关 访存违例预测 的实现也在此描述.
